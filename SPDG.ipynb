{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPDG.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LOEYLCNJ2_WZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sformułowanie problemu\n",
        "\n",
        "Rozważamy problem uczenia klasyfikatora danych sekwencyjnych, który ciągowi \n",
        "$ (x_1,\\dots x_{T_0}) $ przyporządkowuje ciąg $(y_1,\\dots y_{T_0})$, ale bez dostępu do podpisanego zbioru treningowego $\\mathcal{D}_{XY} = \\lbrace(x_1^n, \\dots, x_{T_n}^n), (y_1^n, \\dots,y_{T_n}^n) \\ : \\ n=1,\\dots, M \\rbrace $ (tutaj $T_n$ oznacza długość $n$-tego ciągu), a jedynie do:\n",
        "* zbioru niepodpisanych danych: $\\mathcal{D}_X = \\lbrace(x_1^n, \\dots, x_{T_n}^n)\\ : \\ n=1,\\dots, M \\rbrace$,\n",
        "* modelu n-gram: $p_{LM}(i_1,\\dots ,i_N) = p_{LM}(y_{t-N+1}^n=i_1, \\dots, y_t^n=i^N)$,\n",
        "\n",
        "gdzie $i_1, \\dots, i_N$ są elementami sekwencji (np. słowami/literami), a subskrypt $LM$ oznacza model językowy (*Language Model*)."
      ]
    },
    {
      "metadata": {
        "id": "OOkVSqtO8rVo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 2\n",
        "data_path = './data'\n",
        "\n",
        "transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(),\n",
        "     torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
        "    ])\n",
        "\n",
        "_test = torchvision.datasets.MNIST(\n",
        "    data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "_train = torchvision.datasets.MNIST(\n",
        "    data_path, train=True, download=True, transform=transform)\n",
        "_train.train_data = _train.train_data[:5]\n",
        "_train.train_labels = _train.train_labels[:5]\n",
        "\n",
        "_valid = torchvision.datasets.MNIST(\n",
        "    data_path, train=True, download=True, transform=transform)\n",
        "_valid.train_data = _valid.train_data[50000:]\n",
        "_valid.train_labels = _valid.train_labels[50000:]\n",
        "\n",
        "mnist_loaders = {\n",
        "    'train': torch.utils.data.DataLoader(\n",
        "        _train, batch_size=batch_size, shuffle=True,\n",
        "        pin_memory=True, num_workers=10),\n",
        "    'valid': torch.utils.data.DataLoader(\n",
        "        _valid, batch_size=batch_size, shuffle=False),\n",
        "    'test': torch.utils.data.DataLoader(\n",
        "        _test, batch_size=batch_size, shuffle=False)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GyahDBu3-Bm8",
        "colab_type": "code",
        "outputId": "1f907391-49da-4312-e2d3-9ce9762e681a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "import numpy as np\n",
        "from random import randint as rint\n",
        "from imageio import imwrite\n",
        "import os\n",
        "import datetime\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class args:\n",
        "    N = 10\n",
        "    M = 10\n",
        "    root_path = './dataset'\n",
        "\n",
        "\n",
        "N = args.N # number of digits in the contiguous sequence\n",
        "M = args.M # number of samples\n",
        "\n",
        "data = datasets.MNIST('./MNIST', train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))\n",
        "            ]))\n",
        "\n",
        "\n",
        "dataset_data = np.zeros((M, 28, 0))\n",
        "dataset_labels = np.zeros((M, 28, 0))\n",
        "s = np.append(data.train_labels.view(-1,1,1).repeat(1,28,1).numpy(), data.train_data.numpy(), axis=2)\n",
        "print(s.shape)\n",
        "# print(s[0])\n",
        "for i in range(N):\n",
        "    p = np.random.permutation(s)[:M]\n",
        "    d = p[:,:,1:]\n",
        "    if i == 0:\n",
        "        dataset_data = d\n",
        "    else:\n",
        "        dataset_data = np.append(dataset_data, d, axis=2)\n",
        "    dataset_labels = np.append(dataset_labels, p[:,:,0:1], axis=2)\n",
        "\n",
        "dataset_labels = dataset_labels[:,0,:]\n",
        "print(dataset_labels.shape)\n",
        "# Creates a dataset of 60000 (28*N + (N-1)*overlap) * 36 images\n",
        "# containing N numbers in sequence and their labels\n",
        "images = []\n",
        "if not os.path.exists('./images'): os.makedirs('./images')\n",
        "for i in range(M):\n",
        "    img = np.zeros((28, 0))\n",
        "    # probs = torch.Tensor(range(0, N + 1))\n",
        "    if i == 0: print(img.shape)\n",
        "    img = dataset_data[i,:,:]\n",
        "    images.append(img)\n",
        "    if False:\n",
        "        name = './images/img_' + ''.join(map(lambda x: str(int(x)), dataset_labels[i])) + '.png'\n",
        "        imwrite(name, img.clip(0, 255).astype('uint8'))\n",
        "\n",
        "dataset_data = np.array(images) / 255.0\n",
        "\n",
        "t = datetime.datetime.now().time()\n",
        "if not os.path.exists(args.root_path): os.makedirs(args.root_path)\n",
        "data_path = args.root_path + \"data_\" + str(N) + \"_\" + str(M) + \".npy\"\n",
        "np.save(data_path, dataset_data)\n",
        "print(\"Saved: \", data_path)\n",
        "label_path = args.root_path + \"labels_\" + str(N) + \"_\" + str(M) + \".npy\"\n",
        "np.save(label_path, dataset_labels)\n",
        "print(\"Saved: \", label_path)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 29)\n",
            "(10, 10)\n",
            "(28, 0)\n",
            "Saved:  ./datasetdata_10_10.npy\n",
            "Saved:  ./datasetlabels_10_10.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P47NFYfL-O98",
        "colab_type": "code",
        "outputId": "02c3ba9b-067a-44d0-eb7a-49013068f858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "import numpy as np\n",
        "from random import randint as rint\n",
        "from scipy.misc import imsave\n",
        "# from PIL import Image\n",
        "import os\n",
        "import datetime\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class args:\n",
        "    N = 15\n",
        "    M = 2\n",
        "    root_path = './dataset'\n",
        "\n",
        "\n",
        "N = args.N # number of digits in the contiguous sequence\n",
        "M = args.M # number of samples\n",
        "\n",
        "# space = range(200, 10000)\n",
        "# overlap = range(15, 25) # bigger -> more overlapped\n",
        "space = range(200, 201)\n",
        "overlap = range(10, 11) # bigger -> more overlapped\n",
        "\n",
        "data = datasets.MNIST('./MNIST', train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))\n",
        "            ]))\n",
        "\n",
        "\n",
        "dataset_data = np.zeros((M, N, 28, 28))\n",
        "dataset_labels = np.zeros((M, N))\n",
        "\n",
        "for i in range(M):\n",
        "    p = np.random.choice(np.arange(60000), size=N)\n",
        "    print(p)\n",
        "    dataset_data[i,:,:,:] = data.train_data.numpy()[p] \n",
        "    dataset_labels[i,:] = data.train_labels.numpy()[p]\n",
        "\n",
        "    \n",
        "images = []\n",
        "if not os.path.exists('./images'): os.makedirs('./images')\n",
        "for i in range(M):\n",
        "    img = np.zeros((28, 0))\n",
        "    # probs = torch.Tensor(range(0, N + 1))\n",
        "    for j in range(N):\n",
        "        img = np.append(img, dataset_data[i,j,:,:], axis=1)\n",
        "    images.append(img)\n",
        "    name = './images/img_' + ''.join(map(lambda x: str(int(x)), dataset_labels[i])) + '.png'\n",
        "    imsave(name, img.clip(0, 255))\n",
        "\n",
        "dataset_data = np.array(images) / 255.0\n",
        "\n",
        "if not os.path.exists(args.root_path): os.makedirs(args.root_path)\n",
        "data_path = args.root_path + \"/data_\" + str(N) + \"_\" + str(M) + \".npy\"\n",
        "np.save(data_path, dataset_data)\n",
        "print(\"Saved: \", data_path)\n",
        "label_path = args.root_path + \"/labels_\" + str(N) + \"_\" + str(M) + \".npy\"\n",
        "np.save(label_path, dataset_labels)\n",
        "print(\"Saved: \", label_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 4061 36119 20219 14537 21177 18056 42388 50108 45059  6006 14678 56444\n",
            " 37762 46456 56450]\n",
            "[16803 15269 42161 35700 47915 52922  9290 23722 54513 32684 34808 55108\n",
            "  2420 19423 30286]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved:  ./dataset/data_15_2.npy\n",
            "Saved:  ./dataset/labels_15_2.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tawAjrWA0iSg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}